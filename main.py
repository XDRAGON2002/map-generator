# -*- coding: utf-8 -*-
"""STAI.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Cfs8KYWmg_YpEI8UA7MNK3wJ0pKpmAOO
"""

from google.colab import drive

drive.mount("/content/gdrive")

ls ./gdrive/MyDrive/STAI/maps

import os
import numpy as np
from PIL import Image
import matplotlib.pyplot as plt

train_paths = []
val_paths = []

for i in os.listdir("./gdrive/MyDrive/STAI/maps/train"):
    train_paths.append(f"./gdrive/MyDrive/STAI/maps/train/{i}")
for i in os.listdir("./gdrive/MyDrive/STAI/maps/val"):
    val_paths.append(f"./gdrive/MyDrive/STAI/maps/val/{i}")

len(train_paths), len(val_paths)

import torch
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms

class MapsDataset(Dataset):
    def __init__(self, paths):
        self.transforms = transforms.Compose([
            transforms.Resize((256, 512), Image.BICUBIC),
        ])
        self.paths = paths
    
    def __getitem__(self, idx):
        img = Image.open(self.paths[idx]).convert("RGB")
        img = self.transforms(img)
        img = np.array(img, dtype="float32")
        img = (img - 127.5) / 127.5
        img = transforms.ToTensor()(img)
        src, tar = img[:, :, :256], img[:, :, 256:]
        return {"src": src, "tar": tar}
    
    def __len__(self):
        return len(self.paths)

img = Image.open("./gdrive/MyDrive/STAI/maps/train/1.jpg").convert("RGB")
img = transforms.Resize((256, 512), Image.BICUBIC)(img)
img = np.array(img)
img = (img - 127.5) / 127.5
img = transforms.ToTensor()(img)
src, tar = img[:, :, :256], img[:, :, 256:]
print(src.shape, tar.shape)

train_ds = MapsDataset(train_paths)
val_ds = MapsDataset(val_paths)

train_ds[0]["src"].shape

train_dl = DataLoader(train_ds, batch_size=1)
val_dl = DataLoader(val_ds, batch_size=1)

data = next(iter(train_dl))

torch.permute(data["src"].squeeze(), (1, 2, 0)).shape

plt.imshow(torch.permute(data["src"].squeeze(), (1, 2, 0)))

plt.imshow(torch.permute(data["tar"].squeeze(), (1, 2, 0)))

plt.imshow(torch.permute(torch.cat([data["src"], data["tar"]], 3).squeeze(), (1, 2, 0)))

from torch import nn, optim

class Discriminator(nn.Module):
    def __init__(self):
        super().__init__()

        self.conv1 = nn.Conv2d(6, 64, 4, stride=2)
        self.conv2 = nn.Conv2d(64, 128, 4, stride=2)
        self.conv3 = nn.Conv2d(128, 256, 4, stride=2)
        self.conv4 = nn.Conv2d(256, 512, 4, stride=2)
        self.conv5 = nn.Conv2d(512, 512, 4, stride=1)
        self.conv6 = nn.Conv2d(512, 1, 4, stride=1)

        self.batch_norm1 = nn.BatchNorm2d(128)
        self.batch_norm2 = nn.BatchNorm2d(256)
        self.batch_norm3 = nn.BatchNorm2d(512)
        self.batch_norm4 = nn.BatchNorm2d(512)

        self.leaky_relu = nn.LeakyReLU(0.2)
        self.sigmoid = nn.Sigmoid()
    
    def forward(self, X):
        X = self.leaky_relu(self.conv1(X))
        X = self.leaky_relu(self.batch_norm1(self.conv2(X)))
        X = self.leaky_relu(self.batch_norm2(self.conv3(X)))
        X = self.leaky_relu(self.batch_norm3(self.conv4(X)))
        X = self.leaky_relu(self.batch_norm4(self.conv5(X)))
        X = self.sigmoid(self.conv6(X))
        return X

class Generator(nn.Module):
    def __init__(self):
        super().__init__()

        self.d_conv1 = nn.Conv2d(3, 64, 4, stride=2, padding=1)
        self.d_conv2 = nn.Conv2d(64, 128, 4, stride=2, padding=1)
        self.d_conv3 = nn.Conv2d(128, 256, 4, stride=2, padding=1)
        self.d_conv4 = nn.Conv2d(256, 512, 4, stride=2, padding=1)
        self.d_conv5 = nn.Conv2d(512, 512, 4, stride=2, padding=1)
        self.d_conv6 = nn.Conv2d(512, 512, 4, stride=2, padding=1)
        self.d_conv7 = nn.Conv2d(512, 512, 4, stride=2, padding=1)

        self.b_conv = nn.Conv2d(512, 512, 4, stride=1, padding=1)

        self.u_conv1 = nn.ConvTranspose2d(512, 512, 4, stride=1, padding=1)
        self.u_conv2 = nn.ConvTranspose2d(512 * 2, 512, 4, stride=2, padding=1)
        self.u_conv3 = nn.ConvTranspose2d(512 * 2, 512, 4, stride=2, padding=1)
        self.u_conv4 = nn.ConvTranspose2d(512 * 2, 512, 4, stride=2, padding=1)
        self.u_conv5 = nn.ConvTranspose2d(512 * 2, 256, 4, stride=2, padding=1)
        self.u_conv6 = nn.ConvTranspose2d(256 * 2, 128, 4, stride=2, padding=1)
        self.u_conv7 = nn.ConvTranspose2d(128 * 2, 64, 4, stride=2, padding=1)

        self.g_conv = nn.ConvTranspose2d(64 * 2, 3, 4, stride=2, padding=1)

        self.d_batch_norm1 = nn.BatchNorm2d(128)
        self.d_batch_norm2 = nn.BatchNorm2d(256)
        self.d_batch_norm3 = nn.BatchNorm2d(512)
        self.d_batch_norm4 = nn.BatchNorm2d(512)
        self.d_batch_norm5 = nn.BatchNorm2d(512)
        self.d_batch_norm6 = nn.BatchNorm2d(512)

        self.u_batch_norm1 = nn.BatchNorm2d(512)
        self.u_batch_norm2 = nn.BatchNorm2d(512)
        self.u_batch_norm3 = nn.BatchNorm2d(512)
        self.u_batch_norm4 = nn.BatchNorm2d(512)
        self.u_batch_norm5 = nn.BatchNorm2d(256)
        self.u_batch_norm6 = nn.BatchNorm2d(128)
        self.u_batch_norm7 = nn.BatchNorm2d(64)

        self.dropout_1 = nn.Dropout(0.5)
        self.dropout_2 = nn.Dropout(0.5)
        self.dropout_3 = nn.Dropout(0.5)

        self.leaky_relu = nn.LeakyReLU(0.2)
        self.relu = nn.ReLU()
        self.tanh = nn.Tanh()
    
    def forward(self, X):
        d1 = self.leaky_relu(self.d_conv1(X))
        d2 = self.leaky_relu(self.d_batch_norm1(self.d_conv2(d1)))
        d3 = self.leaky_relu(self.d_batch_norm2(self.d_conv3(d2)))
        d4 = self.leaky_relu(self.d_batch_norm3(self.d_conv4(d3)))
        d5 = self.leaky_relu(self.d_batch_norm4(self.d_conv5(d4)))
        d6 = self.leaky_relu(self.d_batch_norm5(self.d_conv6(d5)))
        d7 = self.leaky_relu(self.d_batch_norm6(self.d_conv7(d6)))

        b = self.relu(self.b_conv(d7))

        u1 = self.relu(torch.cat([self.dropout_1(self.u_batch_norm1(self.u_conv1(b))), d7], 1))
        u2 = self.relu(torch.cat([self.dropout_2(self.u_batch_norm2(self.u_conv2(u1))), d6], 1))
        u3 = self.relu(torch.cat([self.dropout_3(self.u_batch_norm3(self.u_conv3(u2))), d5], 1))
        u4 = self.relu(torch.cat([self.u_batch_norm4(self.u_conv4(u3)), d4], 1))
        u5 = self.relu(torch.cat([self.u_batch_norm5(self.u_conv5(u4)), d3], 1))
        u6 = self.relu(torch.cat([self.u_batch_norm6(self.u_conv6(u5)), d2], 1))
        u7 = self.relu(torch.cat([self.u_batch_norm7(self.u_conv7(u6)), d1], 1))

        g = self.tanh(self.g_conv(u7))
        return g

class GAN(nn.Module):
    def __init__(self):
        super().__init__()
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        self.generator = Generator().to(self.device)
        self.discriminator = Discriminator().to(self.device)
        self.GANcriterion = nn.BCEWithLogitsLoss().to(self.device)
        self.L1criterion = nn.L1Loss().to(self.device)
        self.opt_generator = optim.Adam(self.generator.parameters(), lr=0.001)
        self.opt_discriminator = optim.Adam(self.discriminator.parameters(), lr=0.001)
    
    def setup_input(self, data):
        self.src = data["src"].to(self.device)
        self.tar = data["tar"].to(self.device)
    
    def forward(self):
        self.generated_tar = self.generator(self.src)
    
    def set_requires_grad(self, model, requires_grad=True):
        for param in model.parameters():
            param.requires_grad = requires_grad
    
    def backward_discriminator(self):
        generated_map = torch.cat([self.src, self.generated_tar], 1)
        generated_preds = self.discriminator(generated_map.detach())
        real_map = torch.cat([self.src, self.tar], 1)
        real_preds = self.discriminator(real_map)
        loss_discriminator_generated = self.GANcriterion(generated_preds.to(self.device), torch.zeros(generated_preds.shape).to(self.device))
        loss_discriminator_real = self.GANcriterion(real_preds.to(self.device), torch.ones(real_preds.shape).to(self.device))
        loss_discriminator = (loss_discriminator_generated + loss_discriminator_real) * 0.5
        loss_discriminator.backward()
    
    def backward_generator(self):
        generated_map = torch.cat([self.src, self.generated_tar], 1)
        generated_preds = self.discriminator(generated_map.to(self.device))
        loss_generator_gan = self.GANcriterion(generated_preds.to(self.device), torch.ones(generated_preds.shape).to(self.device))
        loss_generator_l1 = self.L1criterion(self.generated_tar.to(self.device), self.tar.to(self.device)) * 100.0
        loss_generator = loss_generator_gan + loss_generator_l1
        loss_generator.backward()

    def optimize(self):
        self.forward()
        self.discriminator.train()
        self.set_requires_grad(self.discriminator, True)
        self.opt_discriminator.zero_grad()
        self.backward_discriminator()
        self.opt_discriminator.step()
        self.generator.train()
        self.set_requires_grad(self.discriminator, False)
        self.opt_generator.zero_grad()
        self.backward_generator()
        self.opt_generator.step()

import time
from tqdm.notebook import tqdm

model = GAN()

epochs = 100

visual = next(iter(val_dl))
for e in range(epochs):
    counter = 0
    for data in tqdm(train_dl):
        model.setup_input(data)
        model.optimize()
        counter += 1
        if counter % 100 == 0:
            print(f"Epoch: {e + 1}")
            print(f"Step: {counter}/{len(train_dl)}")
            model.generator.eval()
            with torch.no_grad():
                model.setup_input(visual)
                model.forward()
            model.generator.train()
            generated_tar = (model.generated_tar.detach() + 1) / 2.0
            real_tar = (model.tar + 1) / 2.0
            src = (model.src + 1) / 2.0
            fig = plt.figure(figsize=(15, 8))
            ax = plt.subplot(3, 1, 1)
            ax.imshow(torch.permute(src.cpu().squeeze(), (1, 2, 0)))
            ax.axis("off")
            ax = plt.subplot(3, 1, 2)
            ax.imshow(torch.permute(real_tar.cpu().squeeze(), (1, 2, 0)))
            ax.axis("off")
            ax = plt.subplot(3, 1, 3)
            ax.imshow(torch.permute(generated_tar.cpu().squeeze(), (1, 2, 0)))
            ax.axis("off")
            plt.show()

